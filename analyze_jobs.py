import csv
from collections import Counter
from typing import List, Dict


CSV_PATH = "job_results.csv"


def load_job_results(path: str = CSV_PATH) -> List[Dict]:
    """
    Load job analysis results from the CSV file generated by job_radar.py.
    Each row is converted into a dict.
    """
    rows: List[Dict] = []

    with open(path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append(row)

    return rows


def split_and_clean(value: str) -> List[str]:
    """
    Split a comma-separated string into a list of normalized tokens.
    Example:
        "python, SQL, data analysis" -> ["python", "sql", "data analysis"]
    """
    if not value:
        return []

    parts = [p.strip().lower() for p in value.split(",")]
    return [p for p in parts if p]


def analyze_skills_and_languages(rows: List[Dict]) -> None:
    """
    Count how often each skill and language appears across all job rows.
    Print top ones.
    """
    skill_counter: Counter = Counter()
    language_counter: Counter = Counter()

    for row in rows:
        skills = split_and_clean(row.get("skills", ""))
        languages = split_and_clean(row.get("languages", ""))

        skill_counter.update(skills)
        language_counter.update(languages)

    print("\n=== Top Skills ===")
    for skill, count in skill_counter.most_common():
        print(f"{skill}: {count}")

    print("\n=== Top Languages ===")
    for lang, count in language_counter.most_common():
        print(f"{lang}: {count}")


def main() -> None:
    print("=== Job Market Analyzer ===")

    rows = load_job_results()
    if not rows:
        print("No rows found in job_results.csv. Run job_radar.py first.")
        return

    print(f"Loaded {len(rows)} job(s) from '{CSV_PATH}'")
    analyze_skills_and_languages(rows)


if __name__ == "__main__":
    main()
